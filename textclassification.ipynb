{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#TEXT **CLASSIFICATION**"
      ],
      "metadata": {
        "id": "A0nnYFArt8Kx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfJ-D7sthZKs",
        "outputId": "6d27639b-184e-4acc-962c-5d5286e9a2ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers einops\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrANGeSIix7R",
        "outputId": "f960199b-42ed-4201-8b52-e524e1a0963d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber\n",
        "# Install the pdfplumber library which is necessary for extracting text from PDF files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8UztOS43EvH",
        "outputId": "692b2b5a-f37a-4f24-823a-569d09b54833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import CrossEncoder\n",
        "import pdfplumber\n",
        "\n",
        "# Load a cross-encoder model to rank venue descriptions based on a query.\n",
        "model = CrossEncoder(\n",
        "    \"jinaai/jina-reranker-v2-base-multilingual\",\n",
        "    automodel_args={\"torch_dtype\": \"auto\"},\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "def extract_venues_from_pdf(pdf_path: str) -> list:\n",
        "    \"\"\"\n",
        "    Extracts venue descriptions from a given PDF file.\n",
        "\n",
        "    Args:\n",
        "    - pdf_path (str): Path to the PDF file containing venue descriptions.\n",
        "\n",
        "    Returns:\n",
        "    - List[str]: List of venue descriptions extracted from the PDF.\n",
        "    \"\"\"\n",
        "    venues = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            # Extract text from each page\n",
        "            text = page.extract_text()\n",
        "            # Assuming each line in the PDF represents a venue description\n",
        "            if text:\n",
        "                venues.extend(text.splitlines())\n",
        "    # Filter out any empty strings from the list\n",
        "    venues = [venue.strip() for venue in venues if venue.strip()]\n",
        "    return venues\n",
        "\n",
        "def extract_venues_from_multiple_pdfs(pdf_paths: list) -> list:\n",
        "    \"\"\"\n",
        "    Extracts venue descriptions from multiple PDF files.\n",
        "\n",
        "    Args:\n",
        "    - pdf_paths (list): List of paths to the PDF files containing venue descriptions.\n",
        "\n",
        "    Returns:\n",
        "    - List[str]: Combined list of venue descriptions extracted from all PDFs.\n",
        "    \"\"\"\n",
        "    all_venues = []\n",
        "    for pdf_path in pdf_paths:\n",
        "        venues = extract_venues_from_pdf(pdf_path)\n",
        "        all_venues.extend(venues)\n",
        "    return all_venues\n",
        "\n",
        "# List of paths to your PDF files\n",
        "pdf_paths = [\"/content/drive/MyDrive/PDF/The Boy Who Cried Wolf.pdf\",\n",
        "             \"/content/drive/MyDrive/PDF/The Lion and the Mouse.pdf\",\n",
        "             \"/content/drive/MyDrive/PDF/The Tortoise and the Hare.pdf\",\n",
        "             \"/content/drive/MyDrive/PDF/DS.pdf\"]  # Replace with the paths to your actual PDF files\n",
        "\n",
        "# Extract venue descriptions from multiple PDF files\n",
        "venues = extract_venues_from_multiple_pdfs(pdf_paths)\n",
        "# Example query describing event venue requirements\n",
        "query = \"data encoding\"\n",
        "\n",
        "# Check if venues list is empty and handle it\n",
        "if not venues:\n",
        "    print(\"No venues found in the provided PDFs.\")\n",
        "else:\n",
        "    # Constructing pairs of query and each venue description\n",
        "    venue_pairs = [[query, venue] for venue in venues]\n",
        "\n",
        "    # Predict scores for each pair to measure relevance to the query\n",
        "    scores = model.predict(venue_pairs, convert_to_tensor=True).tolist()\n",
        "\n",
        "    # Rank the venues based on the query and return the best matches with scores\n",
        "    rankings = model.rank(query, venues, return_documents=True, convert_to_tensor=True)\n",
        "\n",
        "    # Filter out results with Chinese characters in the descriptions\n",
        "    filtered_rankings = [ranking for ranking in rankings if not any('\\u4e00' <= char <= '\\u9fff' for char in ranking['text'])]\n",
        "\n",
        "    # Further filter based on relevant content and a score threshold\n",
        "    relevant_keywords = [\"encoding\", \"data encoding\", \"encoding techniques\"]\n",
        "    threshold = 0.5  # Adjust threshold as needed\n",
        "    final_rankings = [\n",
        "        ranking for ranking in filtered_rankings\n",
        "        if any(keyword.lower() in ranking['text'].lower() for keyword in relevant_keywords) and ranking['score'] >= threshold\n",
        "    ]\n",
        "\n",
        "    print(f\"Query: {query}\")\n",
        "    for ranking in final_rankings:\n",
        "        print(f\"ID: {ranking['corpus_id']}, Score: {ranking['score']:.4f}, Venue Description: {ranking['text']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi0ZbTi8tc2C",
        "outputId": "066dfeed-8d8d-4dcb-9714-b4529b79e99d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: data encoding\n",
            "ID: 45, Score: 0.6992, Venue Description: Encoding is a crucial step in data preprocessing, particularly when dealing with categorical\n",
            "ID: 56, Score: 0.6523, Venue Description: Importance of Encoding in Data Analysis\n",
            "ID: 44, Score: 0.6367, Venue Description: What is Encoding in Data Science?\n",
            "ID: 24, Score: 0.6094, Venue Description: Introduction to Data Science Analysis and Encoding\n",
            "ID: 47, Score: 0.5781, Venue Description: encoding is the process of transforming categorical variables (such as text or labels) into\n",
            "ID: 62, Score: 0.5703, Venue Description: Combining Data Science Analysis with effective Encoding techniques enables data\n"
          ]
        }
      ]
    }
  ]
}